{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOsrfG4NoV2i",
        "outputId": "1ae4912a-9f96-469c-8d5c-f7b2158b44b5",
        "vscode": {
          "languageId": "bat"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 's4'...\n",
            "remote: Enumerating objects: 1966, done.\u001b[K\n",
            "remote: Counting objects: 100% (949/949), done.\u001b[K\n",
            "remote: Compressing objects: 100% (372/372), done.\u001b[K\n",
            "remote: Total 1966 (delta 632), reused 577 (delta 577), pack-reused 1017 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1966/1966), 43.33 MiB | 15.96 MiB/s, done.\n",
            "Resolving deltas: 100% (1140/1140), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/state-spaces/s4.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "939d0OzWoV2l",
        "outputId": "36977ee3-1208-4f19-9a20-bdc21257a224",
        "vscode": {
          "languageId": "bat"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/s4\n",
            "/bin/bash: line 1: conda: command not found\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (1.13.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (1.5.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (3.8.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (4.67.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (13.9.4)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (0.18.0)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (18.1.8)\n",
            "Requirement already satisfied: pytorch-lightning==2.0.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (2.0.4)\n",
            "Requirement already satisfied: hydra-core in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (1.3.2)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (2.3.0)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (0.19.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (0.8.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (3.31.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (4.47.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 24)) (3.2.0)\n",
            "Requirement already satisfied: sktime in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 25)) (0.35.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 27)) (0.60.0)\n",
            "Requirement already satisfied: gluonts in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 28)) (0.16.0)\n",
            "Requirement already satisfied: timm==0.5.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 29)) (0.5.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==2.0.4->-r requirements.txt (line 11)) (2.5.1+cu121)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==2.0.4->-r requirements.txt (line 11)) (6.0.2)\n",
            "Requirement already satisfied: fsspec>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning==2.0.4->-r requirements.txt (line 11)) (2024.9.0)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==2.0.4->-r requirements.txt (line 11)) (1.6.1)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==2.0.4->-r requirements.txt (line 11)) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==2.0.4->-r requirements.txt (line 11)) (4.12.2)\n",
            "Requirement already satisfied: lightning-utilities>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==2.0.4->-r requirements.txt (line 11)) (0.11.9)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm==0.5.4->-r requirements.txt (line 29)) (0.20.1+cu121)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 3)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 3)) (2024.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 4)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 4)) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 5)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 5)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 5)) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 5)) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 5)) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 5)) (3.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->-r requirements.txt (line 7)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->-r requirements.txt (line 7)) (2.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext->-r requirements.txt (line 8)) (2.32.3)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from hydra-core->-r requirements.txt (line 12)) (4.9.3)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 14)) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 14)) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 14)) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 14)) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 14)) (4.25.5)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 14)) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 14)) (2.10.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 14)) (2.19.2)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 14)) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 14)) (75.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 18)) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 18)) (0.27.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 18)) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 18)) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 18)) (0.4.5)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 24)) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 24)) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 24)) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 24)) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 24)) (3.11.10)\n",
            "Requirement already satisfied: scikit-base<0.13.0,>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from sktime->-r requirements.txt (line 25)) (0.12.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->-r requirements.txt (line 27)) (0.43.0)\n",
            "Requirement already satisfied: toolz~=0.10 in /usr/local/lib/python3.10/dist-packages (from gluonts->-r requirements.txt (line 28)) (0.12.1)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb->-r requirements.txt (line 14)) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 24)) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 24)) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 24)) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 24)) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 24)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 24)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 24)) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 24)) (1.18.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 14)) (4.0.11)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->-r requirements.txt (line 7)) (0.1.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb->-r requirements.txt (line 14)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb->-r requirements.txt (line 14)) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext->-r requirements.txt (line 8)) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext->-r requirements.txt (line 8)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext->-r requirements.txt (line 8)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext->-r requirements.txt (line 8)) (2024.12.14)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning==2.0.4->-r requirements.txt (line 11)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning==2.0.4->-r requirements.txt (line 11)) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning==2.0.4->-r requirements.txt (line 11)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->pytorch-lightning==2.0.4->-r requirements.txt (line 11)) (1.3.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 14)) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->pytorch-lightning==2.0.4->-r requirements.txt (line 11)) (3.0.2)\n",
            "/content/s4/extensions/kernels\n",
            "running install\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer or other\n",
            "        standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` and ``easy_install``.\n",
            "        Instead, use pypa/build, pypa/installer or other\n",
            "        standards-based tools.\n",
            "\n",
            "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating structured_kernels.egg-info\n",
            "writing structured_kernels.egg-info/PKG-INFO\n",
            "writing dependency_links to structured_kernels.egg-info/dependency_links.txt\n",
            "writing top-level names to structured_kernels.egg-info/top_level.txt\n",
            "writing manifest file 'structured_kernels.egg-info/SOURCES.txt'\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:497: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "reading manifest file 'structured_kernels.egg-info/SOURCES.txt'\n",
            "writing manifest file 'structured_kernels.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_ext\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:416: UserWarning: The detected CUDA version (12.2) has a minor version mismatch with the version that was used to compile PyTorch (12.1). Most likely this shouldn't be a problem.\n",
            "  warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:426: UserWarning: There are no x86_64-linux-gnu-g++ version bounds defined for CUDA version 12.2\n",
            "  warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')\n",
            "building 'structured_kernels' extension\n",
            "creating build/temp.linux-x86_64-cpython-310\n",
            "x86_64-linux-gnu-g++ -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c cauchy.cpp -o build/temp.linux-x86_64-cpython-310/cauchy.o -g -march=native -funroll-loops -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=structured_kernels -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n",
            "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c cauchy_cuda.cu -o build/temp.linux-x86_64-cpython-310/cauchy_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O2 -lineinfo --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=structured_kernels -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "creating build/lib.linux-x86_64-cpython-310\n",
            "x86_64-linux-gnu-g++ -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -shared -Wl,-O1 -Wl,-Bsymbolic-functions build/temp.linux-x86_64-cpython-310/cauchy.o build/temp.linux-x86_64-cpython-310/cauchy_cuda.o -L/usr/local/lib/python3.10/dist-packages/torch/lib -L/usr/local/cuda/lib64 -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-310/structured_kernels.cpython-310-x86_64-linux-gnu.so\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "copying build/lib.linux-x86_64-cpython-310/structured_kernels.cpython-310-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
            "creating stub loader for structured_kernels.cpython-310-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/structured_kernels.py to structured_kernels.cpython-310.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying structured_kernels.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying structured_kernels.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying structured_kernels.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying structured_kernels.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "__pycache__.structured_kernels.cpython-310: module references __file__\n",
            "creating dist\n",
            "creating 'dist/structured_kernels-0.1.0-py3.10-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing structured_kernels-0.1.0-py3.10-linux-x86_64.egg\n",
            "creating /usr/local/lib/python3.10/dist-packages/structured_kernels-0.1.0-py3.10-linux-x86_64.egg\n",
            "Extracting structured_kernels-0.1.0-py3.10-linux-x86_64.egg to /usr/local/lib/python3.10/dist-packages\n",
            "Adding structured-kernels 0.1.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/structured_kernels-0.1.0-py3.10-linux-x86_64.egg\n",
            "Processing dependencies for structured-kernels==0.1.0\n",
            "Finished processing dependencies for structured-kernels==0.1.0\n",
            "/content/s4\n"
          ]
        }
      ],
      "source": [
        "%cd /content/s4\n",
        "# ============= Set Up =============\n",
        "# Requirements\n",
        "!conda install pytorch==1.13.1 torchvision==0.14.1 torchaudio==0.13.1 pytorch-cuda=11.6 -c pytorch -c nvidia\n",
        "!pip install -r requirements.txt\n",
        "# Structured Kernels\n",
        "%cd extensions/kernels/\n",
        "!python setup.py install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6bztFv3pmuc",
        "outputId": "09502a6c-6744-46e5-999c-2521398d6fb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pybullet\n",
            "  Downloading pybullet-3.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Downloading pybullet-3.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (103.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.2/103.2 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pybullet\n",
            "Successfully installed pybullet-3.2.6\n"
          ]
        }
      ],
      "source": [
        "!pip install pybullet\n",
        "!pip install gymnasium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDkoT6sbpM5j",
        "outputId": "0dcde8ae-5e59-4589-9c71-49234efdc9d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/s4\n"
          ]
        }
      ],
      "source": [
        "%cd /content/s4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g08VOGf8oV2m",
        "outputId": "b04f9683-15c7-4bc5-9a07-693823d502bc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions.kl import kl_divergence\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import os\n",
        "import argparse\n",
        "\n",
        "from models.s4.s4 import S4Block as S4  # Can use full version instead of minimal S4D standalone below\n",
        "from models.s4.s4d import S4D\n",
        "from tqdm.auto import tqdm\n",
        "import copy\n",
        "import gc\n",
        "\n",
        "from typing import Any, List, Tuple\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import gym\n",
        "import pybullet_envs  # PyBulletの環境をgymに登録する\n",
        "from einops import rearrange\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# Dropout broke in PyTorch 1.11\n",
        "if tuple(map(int, torch.__version__.split('.')[:2])) == (1, 11):\n",
        "    print(\"WARNING: Dropout is bugged in PyTorch 1.11. Results may be worse.\")\n",
        "    dropout_fn = nn.Dropout\n",
        "if tuple(map(int, torch.__version__.split('.')[:2])) >= (1, 12):\n",
        "    dropout_fn = nn.Dropout1d\n",
        "else:\n",
        "    dropout_fn = nn.Dropout2d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "hmSpRiG-oV2o"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "best_acc = 0  # best test accuracy\n",
        "start_epoch = 0  # start from epoch 0 or last checkpoint epoch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FgUgCRaoV2o"
      },
      "source": [
        "### ハイパラの設定"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "q_HU1jhioV2q",
        "outputId": "0bbf926e-bbb5-4dbc-ce57-5a42429985ec"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'hyparams/hyparaV1_20250104_0931.json'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-b3563569ef2a>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mcurrent_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mcurrent_time_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%Y%m%d_%H%M\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'hyparams/hyparaV1_{current_time_str}.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'hyparams/hyparaV1_20250104_0931.json'"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import datetime\n",
        "\n",
        "#TODO: このハイパラたちは後で書き換える（学習コード作ってから最後に書いたほうがいい）\n",
        "lr = 0.001\n",
        "weight_decay = 0.01\n",
        "num_workers = 4\n",
        "batch_size = 8\n",
        "d_model = 512\n",
        "d_mlp = 512\n",
        "prenorm = True\n",
        "dropout = 0.2\n",
        "grad_clip = 1000\n",
        "\n",
        "hyperparameters = {\n",
        "    \"lr\": lr,\n",
        "    \"weight_decay\": weight_decay,\n",
        "    \"num_workers\":  num_workers,\n",
        "    \"batch_size\": batch_size,\n",
        "    \"d_model\": d_model,\n",
        "    \"d_mlp\": d_mlp,\n",
        "    \"prenorm\": prenorm,\n",
        "    \"dropout\": dropout,\n",
        "    \"grad_clip\": grad_clip,\n",
        "}\n",
        "\n",
        "# ハイパラの種類が今後増える可能性を踏まえ、ファイル名にversionを記載する(hyparaVxxとなるように)\n",
        "current_time = datetime.datetime.now()\n",
        "current_time_str = current_time.strftime(\"%Y%m%d_%H%M\")\n",
        "with open(f'hyparams/hyparaV1_{current_time_str}.json', 'w') as f:\n",
        "    json.dump(hyperparameters, f, indent=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LO_awH5qoV2r"
      },
      "source": [
        "### 環境のWrapper（カメラに関する）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "LeUt9xnPoV2r"
      },
      "outputs": [],
      "source": [
        "class GymWrapper_PyBullet(object):\n",
        "    \"\"\"\n",
        "    PyBullet環境のためのラッパー\n",
        "    \"\"\"\n",
        "\n",
        "    metadata = {\"render.modes\": [\"human\", \"rgb_array\"]}\n",
        "    reward_range = (-np.inf, np.inf)\n",
        "\n",
        "    # __init__でカメラ位置に関するパラメータ（ cam_dist:カメラ距離，cam_yaw：カメラの水平面での回転，cam_pitch:カメラの縦方向での回転）を受け取り，カメラの位置を調整できるようにします.\n",
        "    # 　同時に画像の大きさも変更できるようにします\n",
        "    def __init__(\n",
        "        self,\n",
        "        env: gym.Env,\n",
        "        cam_dist: int = 3,\n",
        "        cam_yaw: int = 0,\n",
        "        cam_pitch: int = -30,\n",
        "        render_width: int = 320,\n",
        "        render_height: int = 240,\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        コンストラクタ．\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        env : gym.Env\n",
        "            gymで提供されている環境のインスタンス．\n",
        "        cam_dist : int\n",
        "            カメラの距離．\n",
        "        cam_yaw : int\n",
        "            カメラの水平面での回転．\n",
        "        cam_pitch : int\n",
        "            カメラの縦方向での回転．\n",
        "        render_width : int\n",
        "            観測画像の幅．\n",
        "        render_height : int\n",
        "            観測画像の高さ．\n",
        "        \"\"\"\n",
        "        self._env = env\n",
        "\n",
        "        self._render_width = render_width\n",
        "        self._render_height = render_height\n",
        "        self._set_nested_attr(self._env, cam_dist, \"_cam_dist\")\n",
        "        self._set_nested_attr(self._env, cam_yaw, \"_cam_yaw\")\n",
        "        self._set_nested_attr(self._env, cam_pitch, \"_cam_pitch\")\n",
        "        self._set_nested_attr(self._env, render_width, \"_render_width\")\n",
        "        self._set_nested_attr(self._env, render_height, \"_render_height\")\n",
        "\n",
        "    def _set_nested_attr(self, env: gym.Env, value: int, attr: str) -> None:\n",
        "        \"\"\"\n",
        "        多重継承の属性に再帰的にアクセスして値を変更する．\n",
        "        カメラの設定に利用．\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        value : int\n",
        "            設定したい値．\n",
        "        attr : str\n",
        "            変更したい属性の名前．\n",
        "        \"\"\"\n",
        "        if hasattr(env, attr):\n",
        "            setattr(env, attr, value)\n",
        "        else:\n",
        "            self._set_nested_attr(env.env, value, attr)\n",
        "\n",
        "    def __getattr(self, name: str) -> Any:\n",
        "        \"\"\"\n",
        "        環境が保持している属性値を取得するメソッド．\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        name : str\n",
        "            取得したい属性値の名前．\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        _env.name : Any\n",
        "            環境が保持している属性値．\n",
        "        \"\"\"\n",
        "        return getattr(self._env, name)\n",
        "\n",
        "    @property\n",
        "    def observation_space(self) -> gym.spaces.Box:\n",
        "        \"\"\"\n",
        "        観測空間に関する情報を取得するメソッド．\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        space : gym.spaces.Box\n",
        "            観測空間に関する情報（各画素値の最小値，各画素値の最大値，観測データの形状， データの型）．\n",
        "        \"\"\"\n",
        "        width = self._render_width\n",
        "        height = self._render_height\n",
        "        return gym.spaces.Box(0, 255, (height, width, 3), dtype=np.uint8)\n",
        "\n",
        "    @property\n",
        "    def action_space(self) -> gym.spaces.Box:\n",
        "        \"\"\"\n",
        "        行動空間に関する情報を取得するメソッド．\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        space : gym.spaces.Box\n",
        "            行動空間に関する情報（各行動の最小値，各行動の最大値，行動空間の次元， データの型） ．\n",
        "        \"\"\"\n",
        "        return self._env.action_space\n",
        "\n",
        "    # 　元の観測（低次元の状態）は今回は捨てて，env.render()で取得した画像を観測とします.\n",
        "    #  画像，報酬，終了シグナルが得られます.\n",
        "    def step(self, action: np.ndarray) -> (np.ndarray, float, bool, dict):\n",
        "        \"\"\"\n",
        "        環境に行動を与え次の観測，報酬，終了フラグを取得するメソッド．\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        action : np.dnarray (action_dim, )\n",
        "            与える行動．\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        obs : np.ndarray (height, width, 3)\n",
        "            行動を与えたときの次の観測．\n",
        "        reward : float\n",
        "            行動を与えたときに得られる報酬．\n",
        "        done : bool\n",
        "            エピソードが終了したかどうか表すフラグ．\n",
        "        info : dict\n",
        "            その他の環境に関する情報．\n",
        "        \"\"\"\n",
        "        _, reward, done, info = self._env.step(action)\n",
        "        obs = self._env.render(mode=\"rgb_array\") # 今回状態として画像を扱いたいため\n",
        "        return obs, reward, done, info\n",
        "\n",
        "    def reset(self) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        環境をリセットするためのメソッド．\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        obs : np.ndarray (height, width, 3)\n",
        "            環境をリセットしたときの初期の観測．\n",
        "        \"\"\"\n",
        "        self._env.reset()\n",
        "        obs = self._env.render(mode=\"rgb_array\")\n",
        "        return obs\n",
        "\n",
        "    def render(self, mode=\"human\", **kwargs) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        観測をレンダリングするためのメソッド．\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        mode : str\n",
        "            レンダリング方法に関するオプション． (default='human')\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        obs : np.ndarray (height, width, 3)\n",
        "            観測をレンダリングした結果．\n",
        "        \"\"\"\n",
        "        return self._env.render(mode, **kwargs)\n",
        "\n",
        "    def close(self) -> None:\n",
        "        \"\"\"\n",
        "        環境を閉じるためのメソッド．\n",
        "        \"\"\"\n",
        "        self._env.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mu7zty7oV2s"
      },
      "source": [
        "#### カメラに関するWrapperのテスト"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        },
        "id": "bssBjMXHoV2s",
        "outputId": "fe2b40a8-6b48-407c-f03a-ea3c6f44439f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:174: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed a `seed` instead of using `Env.seed` for resetting the environment random number generator.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:190: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `return_info` to return information from the environment resetting.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:195: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:280: UserWarning: \u001b[33mWARN: No render modes was declared in the environment (env.metadata['render_modes'] is None or not defined), you may have trouble when calling `.render()`.\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "env = gym.make(\"HalfCheetahBulletEnv-v0\")\n",
        "# カメラのパラメータを与えてカメラの位置と角度，画像の大きさを調整\n",
        "env = GymWrapper_PyBullet(\n",
        "    env, cam_dist=2, cam_pitch=0, render_width=64, render_height=64\n",
        ")\n",
        "\n",
        "env.reset()\n",
        "image = env.render(mode=\"rgb_array\")\n",
        "plt.imshow(image)\n",
        "plt.show()\n",
        "env.close()\n",
        "del env"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKpfbv9loV2s"
      },
      "source": [
        "### 環境のWrapper（行動の連続入力に関する）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "9pVE1R8koV2t"
      },
      "outputs": [],
      "source": [
        "class RepeatAction(gym.Wrapper):\n",
        "    \"\"\"\n",
        "    同じ行動を指定された回数自動的に繰り返すラッパー．観測は最後の行動に対応するものになる\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, env: GymWrapper_PyBullet, skip: int = 4) -> None:\n",
        "        \"\"\"\n",
        "        コンストラクタ．\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        env : GymWrapper_PyBullet\n",
        "            環境のインスタンス．今回は先程定義したラッパーでラップした環境を利用する．\n",
        "        skip : int\n",
        "            同じ行動を繰り返す回数．\n",
        "        \"\"\"\n",
        "        gym.Wrapper.__init__(self, env)\n",
        "        self._skip = skip\n",
        "\n",
        "    def reset(self) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        環境をリセットするためのメソッド．\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        obs : np.ndarray (width, height, 3)\n",
        "            環境をリセットしたときの初期の観測．\n",
        "        \"\"\"\n",
        "        return self.env.reset()\n",
        "\n",
        "    def step(self, action: np.ndarray) -> (np.ndarray, float, bool, dict):\n",
        "        \"\"\"\n",
        "        環境に行動を与え次の観測，報酬，終了フラグを取得するメソッド．\n",
        "        与えられた行動をskipの回数だけ繰り返した結果を返す．\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        action : np.ndarray (action_dim, )\n",
        "            与える行動．\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        obs : np.ndarray (width, height, 3)\n",
        "            行動をskipの回数だけ繰り返したあとの観測．\n",
        "        total_reawrd : float\n",
        "            行動をskipの回数だけ繰り返したときの報酬和．\n",
        "        done : bool\n",
        "            エピソードが終了したかどうか表すフラグ．\n",
        "        info : dict\n",
        "            その他の環境に関する情報．\n",
        "        \"\"\"\n",
        "        total_reward = 0.0\n",
        "        for _ in range(self._skip):\n",
        "            obs, reward, done, info = self.env.step(action)\n",
        "            total_reward += reward\n",
        "            if done:\n",
        "                break\n",
        "        return obs, total_reward, done, info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJzUltaMoV2t"
      },
      "source": [
        "#### Wrapperを通した環境を作る関数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "AxP0b5VaoV2t"
      },
      "outputs": [],
      "source": [
        "def make_env() -> RepeatAction:\n",
        "    \"\"\"\n",
        "    作成たラッパーをまとめて適用して環境を作成する関数．\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    env : RepeatAction\n",
        "        ラッパーを適用した環境．\n",
        "    \"\"\"\n",
        "    env = gym.make(\"HalfCheetahBulletEnv-v0\")  # 環境を読み込む．今回はHalfCheetah\n",
        "    # Dreamerでは観測は64x64のRGB画像\n",
        "    env = GymWrapper_PyBullet(\n",
        "        env, cam_dist=2, cam_pitch=0, render_width=64, render_height=64\n",
        "    )\n",
        "    env = RepeatAction(env, skip=2)  # DreamerではActionRepeatは2\n",
        "    return env"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTf30JzooV2u"
      },
      "source": [
        "### Replay Buffer\n",
        "連続した経験をとってくるのでDQNとは少し違う"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "PKX042qhoV2u"
      },
      "outputs": [],
      "source": [
        "# 　今回のReplayBuffer\n",
        "class ReplayBuffer(object):\n",
        "    \"\"\"\n",
        "    RNNを用いて訓練するのに適したリプレイバッファ．\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, capacity: int, observation_shape: List[int], action_dim: int\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        コンストラクタ．\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        capacity : int\n",
        "            リプレイバッファにためておくことができる経験の上限．\n",
        "        observation_shape : List[int]\n",
        "            環境から与えられる観測の形状．\n",
        "        action_dim : int\n",
        "            行動空間の次元数．\n",
        "        \"\"\"\n",
        "        self.capacity = capacity\n",
        "\n",
        "        self.observations = np.zeros((capacity, *observation_shape), dtype=np.uint8)\n",
        "        self.actions = np.zeros((capacity, action_dim), dtype=np.float32)\n",
        "        self.rewards = np.zeros((capacity, 1), dtype=np.float32)\n",
        "        self.done = np.zeros((capacity, 1), dtype=bool)\n",
        "        # self.done = np.zeros((capacity, 1), dtype=np.bool)\n",
        "\n",
        "        self.index = 0\n",
        "        self.is_filled = False\n",
        "\n",
        "    def push(\n",
        "        self, observation: np.ndarray, action: np.ndarray, reward: float, done: bool\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        リプレイバッファに経験を追加するメソッド．\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        observation : np.ndarray (64, 64, 3)\n",
        "            環境から得られた観測．\n",
        "        action : np.ndarray (action_dim, )\n",
        "            エージェントがとった（もしくは経験を貯める際のランダムな）行動．\n",
        "        reward : float\n",
        "            観測に対して行動をとったときに得られる報酬．\n",
        "        done : bool\n",
        "            エピソードが終了するかどうかのフラグ．\n",
        "        \"\"\"\n",
        "        self.observations[self.index] = observation\n",
        "        self.actions[self.index] = action\n",
        "        self.rewards[self.index] = reward\n",
        "        self.done[self.index] = done\n",
        "\n",
        "        # indexは巡回し，最も古い経験を上書きする\n",
        "        if self.index == self.capacity - 1:\n",
        "            self.is_filled = True\n",
        "        self.index = (self.index + 1) % self.capacity\n",
        "\n",
        "    def sample(self, batch_size: int, chunk_length: int) -> Tuple[np.ndarray]:\n",
        "        \"\"\"\n",
        "        経験をリプレイバッファからサンプルします．（ほぼ）一様なサンプルです．\n",
        "        結果として返ってくるのは観測（画像），行動，報酬，終了シグナルについての(batch_size, chunk_length, 各要素の次元)の配列です．\n",
        "        各バッチは連続した経験になっています．\n",
        "        注意: chunk_lengthをあまり大きな値にすると問題が発生する場合があります．\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        batch_size : int\n",
        "            バッチサイズ．\n",
        "        chunk_length : int\n",
        "            バッチあたりの系列長．\n",
        "\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        sampled_observations : np.ndarray (batch size, chunk length, 3, 64, 64)\n",
        "            バッファからサンプリングされた観測．\n",
        "        sampled_actions : np.ndarray (batch size, chunk length, action dim)\n",
        "            バッファからサンプリングされた行動．\n",
        "        sampled_rewards : np.ndarray (batch size, chunk length, 1)\n",
        "            バッファからサンプリングされた報酬．\n",
        "        sampled_done : np.ndarray (batch size, chunk length, 1)\n",
        "            バッファからサンプリングされたエピソードの終了フラグ．\n",
        "        \"\"\"\n",
        "        episode_borders = np.where(self.done)[0]\n",
        "        sampled_indexes = []\n",
        "        for _ in range(batch_size):\n",
        "            cross_border = True\n",
        "            while cross_border:\n",
        "                initial_index = np.random.randint(len(self) - chunk_length + 1)\n",
        "                final_index = initial_index + chunk_length - 1\n",
        "                cross_border = np.logical_and(\n",
        "                    initial_index <= episode_borders, episode_borders < final_index\n",
        "                ).any()  # 論理積\n",
        "            sampled_indexes += list(range(initial_index, final_index + 1))\n",
        "\n",
        "        sampled_observations = self.observations[sampled_indexes].reshape(\n",
        "            batch_size, chunk_length, *self.observations.shape[1:]\n",
        "        )\n",
        "        sampled_actions = self.actions[sampled_indexes].reshape(\n",
        "            batch_size, chunk_length, self.actions.shape[1]\n",
        "        )\n",
        "        sampled_rewards = self.rewards[sampled_indexes].reshape(\n",
        "            batch_size, chunk_length, 1\n",
        "        )\n",
        "        sampled_done = self.done[sampled_indexes].reshape(batch_size, chunk_length, 1)\n",
        "        return sampled_observations, sampled_actions, sampled_rewards, sampled_done\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        \"\"\"\n",
        "        バッファに貯められている経験の数を返すメソッド．\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        length : int\n",
        "            バッファに貯められている経験の数．\n",
        "        \"\"\"\n",
        "        return self.capacity if self.is_filled else self.index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IeElUxMoV2u"
      },
      "source": [
        "#### 観測の前処理を行う関数\n",
        "ラッパーとして最初から適用してしまわないのは，リプレイバッファにはより容量の小さなnp．uint8の形式で保存しておきたいためです．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "YwMN-_OOoV2u"
      },
      "outputs": [],
      "source": [
        "def preprocess_obs(obs: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    画像を正規化する．[0, 255] -> [-0.5, 0.5]．\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    obs : np.ndarray (64, 64, 3) or (chank length, batch size, 64, 64, 3)\n",
        "        環境から得られた観測．画素値は[0, 255]．\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    normalized_obs : np.ndarray (64, 64, 3) or (chank length, batch size, 64, 64, 3)\n",
        "        画素値を[-0.5, 0.5]で正規化した観測．\n",
        "    \"\"\"\n",
        "    obs = obs.astype(np.float32)\n",
        "    normalized_obs = obs / 255.0 - 0.5\n",
        "    return normalized_obs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOqUE9TCoV2v"
      },
      "source": [
        "#### λ-returnを計算する関数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SW_a1HQsoV2v"
      },
      "outputs": [],
      "source": [
        "def lambda_target(\n",
        "    rewards: torch.Tensor, values: torch.Tensor, gamma: float, lambda_: float\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    価値関数の学習のためのλ-returnを計算する関数．\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    rewards : torch.Tensor (imagination_horizon, batch size * (chank length - 1))\n",
        "        報酬モデルによる報酬の推定値．\n",
        "    values : torch.Tensor (imagination_horizon, batch size * (chank length - 1))\n",
        "        価値関数を近似するValueモデルによる状態価値観数の推定値．\n",
        "    gamma : float\n",
        "        割引率．\n",
        "    lambda_ : float\n",
        "        λ-returnのパラメータλ．\n",
        "\n",
        "    V_lambda : torch.Tensor (imagination_horizon, batch size * (chank length - 1))\n",
        "        各状態に対するλ-returnの値．\n",
        "    \"\"\"\n",
        "    V_lambda = torch.zeros_like(rewards, device=rewards.device)\n",
        "\n",
        "    H = rewards.shape[0] - 1\n",
        "    V_n = torch.zeros_like(rewards, device=rewards.device)\n",
        "    V_n[H] = values[H]\n",
        "    for n in range(1, H + 1):\n",
        "        # まずn-step returnを計算します\n",
        "        # 注意: 系列が途中で終わってしまったら，可能な中で最大のnを用いたn-stepを使います\n",
        "        V_n[:-n] = (gamma**n) * values[n:]\n",
        "        for k in range(1, n + 1):\n",
        "            if k == n:\n",
        "                V_n[:-n] += (gamma ** (n - 1)) * rewards[k:]\n",
        "            else:\n",
        "                V_n[:-n] += (gamma ** (k - 1)) * rewards[k : -n + k]\n",
        "\n",
        "        # lambda_でn-step returnを重みづけてλ-returnを計算します\n",
        "        if n == H:\n",
        "            V_lambda += (lambda_ ** (H - 1)) * V_n\n",
        "        else:\n",
        "            V_lambda += (1 - lambda_) * (lambda_ ** (n - 1)) * V_n\n",
        "\n",
        "    return V_lambda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhNpM4fRoV2v"
      },
      "source": [
        "## ここからはモデルの実装編"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkMC4L_coV2v"
      },
      "source": [
        "### S4Block (p26 Figure21参照)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PePcmo4koV2v",
        "outputId": "4cbe96f7-36bf-49ef-fa43-d0cb5ae73756"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "class S4Block(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        d_model=256,\n",
        "        d_mlp = 512,\n",
        "        n_layers=2,\n",
        "        dropout=0.2,\n",
        "        prenorm=True,\n",
        "    ):\n",
        "        super(S4Block, self).__init__()\n",
        "\n",
        "        self.prenorm = prenorm\n",
        "\n",
        "        # Stack S4 layers as residual blocks\n",
        "        self.norms = nn.ModuleList()\n",
        "        self.s4_layers = nn.ModuleList()\n",
        "        self.dropouts = nn.ModuleList()\n",
        "        for _ in range(n_layers):\n",
        "            self.norms.append(nn.LayerNorm(d_model))\n",
        "            self.s4_layers.append(\n",
        "                S4D(d_model, dropout=dropout, transposed=True, lr=min(0.001, lr))\n",
        "            )\n",
        "            self.dropouts.append(dropout_fn(dropout))\n",
        "\n",
        "        self.norm_mlp = nn.Sequential(\n",
        "            nn.LayerNorm(d_model),\n",
        "            nn.Linear(d_model, d_mlp),\n",
        "            nn.GELU(),\n",
        "            dropout_fn(dropout),\n",
        "            nn.Linear(d_mlp, d_model),\n",
        "            dropout_fn(dropout))\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Input x is shape (B, L, d_model), L is the length of continuous observations, B is the batch size\n",
        "        \"\"\"\n",
        "        x = x.transpose(-1, -2)  # (B, L, d_model) -> (B, d_model, L)\n",
        "        for norm, s4, dropout in \\\n",
        "            zip(self.norms, self.s4_layers, self.dropouts):\n",
        "            # Each iteration of this loop will map (B, d_model, L) -> (B, d_model, L)\n",
        "\n",
        "            z = x\n",
        "            if self.prenorm:\n",
        "                # Prenorm\n",
        "                z = norm(z.transpose(-1, -2)).transpose(-1, -2)\n",
        "\n",
        "            # Apply S4 block: we ignore the state input and output\n",
        "            z, _ = s4(z)\n",
        "\n",
        "            # Dropout on the output of the S4 block\n",
        "            z = dropout(z)\n",
        "\n",
        "            # Residual connection\n",
        "            x = z + x\n",
        "\n",
        "            if not self.prenorm:\n",
        "                # Postnorm\n",
        "                x = norm(x.transpose(-1, -2)).transpose(-1, -2)\n",
        "\n",
        "        x = x.transpose(-1, -2)  # (B, d_model, L) -> (B, L, d_model)\n",
        "\n",
        "        #TODO: x_にも操作が反映されてたりしないか確認する. residual connectionのため\n",
        "        x_ = x\n",
        "        x = x_ + self.norm_mlp(x)\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6kDdlwHoV2w"
      },
      "source": [
        "### HistoryEncoder\n",
        "HistoryEncoderはPriorに当たる<br>\n",
        "(次元を表す変数が\"*\\_dim\"だったり\"d\\_\\*\"だったりして紛らわしかもしれません)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-kI32yUoV2w",
        "outputId": "2501fc61-b62e-41b7-d5cd-81a3732d00dc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "class HistoryEncoder(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "\n",
        "        z_dim, # z_dim=1024にする予定. Encoderからの出力zの次元と合わせる必要がある\n",
        "        action_dim,\n",
        "        gMLP_dim=512,\n",
        "\n",
        "        history_dim=256,\n",
        "        S4_mlp_dim=512,\n",
        "        S4_n_layers=2,\n",
        "        dropout=0.2,\n",
        "        prenorm=True,\n",
        "\n",
        "        zMLP_dim=512,\n",
        "        class_size=32,\n",
        "        category_size=32,\n",
        "    ):\n",
        "        super(HistoryEncoder, self).__init__()\n",
        "        self.class_size = class_size\n",
        "        self.category_size = category_size\n",
        "        self.gMLP = nn.Sequential(\n",
        "            nn.Linear(z_dim + action_dim, gMLP_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(gMLP_dim, history_dim)\n",
        "        )\n",
        "\n",
        "        self.S4 = S4Block(d_model=history_dim, d_mlp=S4_mlp_dim, n_layers=S4_n_layers, dropout=dropout, prenorm=prenorm)\n",
        "\n",
        "        self.zMLP = nn.Sequential(\n",
        "            nn.Linear(history_dim, zMLP_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(zMLP_dim, z_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, z, action):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        z : torch.Tensor (batch_size, L, z_dim)\n",
        "            環境から得られた観測画像の潜在表現. この時点ではone-hot vectorである\n",
        "\n",
        "        action : torch.Tensor (batch_size, L, action_dim)\n",
        "\n",
        "        Returns\n",
        "        ----------\n",
        "        h : torch.Tensor (batch_size, L, 1024)\n",
        "            観測画像を埋め込み、カテゴリカル分布からサンプルしたもの(この時点ではone-hot vector)\n",
        "            勾配を通してあるのはreward lossからの勾配を計算するため\n",
        "\n",
        "        z : torch.Tensor (batch_size, L, z_dim)\n",
        "            次の環境の観測画像の潜在表現. この時点ではone-hot vectorである\n",
        "\n",
        "        dist: torch.distribution\n",
        "            zの分布.ELBOのKL-divergenceを計算するために必要\n",
        "\n",
        "        dist_no_grad: torch.distribution\n",
        "            zの分布.ELBOのKL-divergenceを計算するために必要\n",
        "        \"\"\"\n",
        "        g = self.gMLP(torch.cat([z, action], dim=-1))\n",
        "        h = self.S4(g)\n",
        "        logits = self.zMLP(h).reshape(*h.shape[:-1], self.category_size, self.class_size) # (batch_size, L, 1024) -> (batch_size, L, 32, 32)\n",
        "        probs = torch.softmax(logits, dim=-1) * 0.99 + (0.01 / self.class_size)\n",
        "        dist = torch.distributions.OneHotCategorical(probs=probs)\n",
        "        dist_no_grad = torch.distributions.OneHotCategorical(probs=probs.detach())\n",
        "        stoch = dist.sample()\n",
        "        stoch += probs - probs.detach() # using \"straight-through gradients\"\n",
        "        z = torch.flatten(stoch, start_dim=-2, end_dim=-1)\n",
        "\n",
        "        return h, z, dist, dist_no_grad\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiIAlKWEoV2w"
      },
      "source": [
        "### Encoder, Decoder\n",
        "EncoderはPosteriorに当たる<br>\n",
        "(Decodeで画像にする必要はあるか？評価する上では画像にする必要はありそうだけど実際にモデルとしては軽いほうがいい)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oZJZuF1oV2x",
        "outputId": "61a109bd-95b0-4778-ac9f-574c4ff5cc30"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "class Encoder(nn.Module):\n",
        "    \"\"\"\n",
        "    (input_dim, 64, 64)の画像を(1024,)のベクトルに変換する\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_dim=3, # grayscaleなら1\n",
        "        category_size=32,\n",
        "        class_size=32,\n",
        "    ):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.cv1 = nn.Conv2d(input_dim, 32, kernel_size=4, stride=2) # (input_dim, 64, 64) -> (32, 31, 31)\n",
        "        self.cv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2) # (32, 31, 31) -> (64, 14, 14)\n",
        "        self.cv3 = nn.Conv2d(64, 128, kernel_size=4, stride=2) # (64, 14, 14) -> (128, 6, 6)\n",
        "        self.cv4 = nn.Conv2d(128, 256, kernel_size=4, stride=2) # (128, 6, 6) -> (256, 2, 2)\n",
        "        self.category_size = category_size\n",
        "        self.class_size = class_size\n",
        "\n",
        "    def forward(self, obs):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        obs : torch.Tensor (batch_size, L, input_dim, 64, 64), Lは連続した観測画像の系列長\n",
        "            環境から得られた観測画像\n",
        "\n",
        "        Returns\n",
        "        ----------\n",
        "        z : torch.Tensor (batch_size, L, 1024)\n",
        "            観測画像を埋め込み、カテゴリカル分布からサンプルしたもの(この時点ではone-hot vector)\n",
        "            勾配を通してあるのはreward lossからの勾配を計算するため\n",
        "\n",
        "        dist: torch.distribution\n",
        "            zの分布.ELBOのKL-divergenceを計算するために必要\n",
        "\n",
        "        dist_no_grad: torch.distribution\n",
        "            zの分布.ELBOのKL-divergenceを計算するために必要\n",
        "        \"\"\"\n",
        "        B, L = obs.shape[:2]\n",
        "        hidden = F.silu(self.cv1(obs.reshape(B * L, *obs.shape[2:])))\n",
        "        hidden = F.silu(self.cv2(hidden))\n",
        "        hidden = F.silu(self.cv3(hidden))\n",
        "        logits = F.silu(self.cv4(hidden)).reshape(B, L, self.category_size, self.class_size) # (batch_size, L, 256, 2, 2) -> (batch_size, L,, category_size, class_size)\n",
        "        probs = torch.softmax(logits, dim=-1) * 0.99 + (0.01 / self.class_size)\n",
        "        dist = torch.distributions.OneHotCategorical(probs=probs)\n",
        "        dist_no_grad = torch.distributions.OneHotCategorical(probs=probs.detach())\n",
        "        stoch = dist.sample()\n",
        "        stoch += probs - probs.detach() # using \"straight-through gradients\"\n",
        "        z = torch.flatten(stoch, start_dim=-2, end_dim=-1)\n",
        "\n",
        "        return z, dist, dist_no_grad\n",
        "\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    \"\"\"\n",
        "    (1024,)のベクトルを(input_dim, 64, 64)の画像に変換する\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        output_dim=3, # grayscaleなら1\n",
        "        z_dim=1024,\n",
        "        history_dim=1024,\n",
        "    ):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.fc = nn.Linear(z_dim + history_dim, 1024)\n",
        "        self.cv1 = nn.ConvTranspose2d(1024, 128, kernel_size=5, stride=2) # (1024, 1, 1) -> (128, 5, 5)\n",
        "        self.cv2 = nn.ConvTranspose2d(128, 64, kernel_size=5, stride=2) # (128, 5, 5) -> (64, 13, 13)\n",
        "        self.cv3 = nn.ConvTranspose2d(64, 32, kernel_size=6, stride=2) # (64, 13, 13) -> (32, 30, 30)\n",
        "        self.cv4 = nn.ConvTranspose2d(32, output_dim, kernel_size=6, stride=2) # (32, 30, 30) -> (input_dim, 64, 64)\n",
        "\n",
        "    def forward(self, h, z):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        h: torch.Tensor (batch_size, L, history_dim)\n",
        "            これまでの履歴(S4Blockからの出力)\n",
        "\n",
        "        z : torch.Tensor (batch_size, L, z_dim)\n",
        "            次の観測の潜在表現\n",
        "\n",
        "        Returns\n",
        "        ----------\n",
        "        obs : torch.Tensor (batch_size, L, output_dim, 64, 64)\n",
        "            次の観測画像\n",
        "        \"\"\"\n",
        "        B, L = h.shape[:2]\n",
        "        hidden = self.fc(torch.cat([z, h], dim=-1))\n",
        "        hidden = hidden.view(B*L, 1024, 1, 1)\n",
        "        hidden = F.silu(self.cv1(hidden))\n",
        "        hidden = F.silu(self.cv2(hidden))\n",
        "        hidden = F.silu(self.cv3(hidden))\n",
        "        obs = self.cv4(hidden)\n",
        "\n",
        "        return obs.reshape(B, L, obs.shape[-3:])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5WIpq6xoV2x"
      },
      "source": [
        "### RewardModel\n",
        "報酬モデル. 1層のMLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "LDVB0EnToV2x"
      },
      "outputs": [],
      "source": [
        "class RewardModel(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        history_dim,\n",
        "        z_dim,\n",
        "        mlp_dim=512,\n",
        "    ):\n",
        "        super(RewardModel, self).__init__()\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(history_dim + z_dim, mlp_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(mlp_dim, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, h, z):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        h: torch.Tensor (batch_size, L, history_dim)\n",
        "            これまでの履歴\n",
        "\n",
        "        z : torch.Tensor (batch_size, L, z_dim)\n",
        "            次の観測の潜在表現\n",
        "\n",
        "        Returns\n",
        "        ----------\n",
        "        reward : torch.Tensor (batch_size, L, 1)\n",
        "            報酬の予測値\n",
        "        \"\"\"\n",
        "        reward = self.fc1(torch.cat([h, z], dim=-1))\n",
        "\n",
        "        return reward\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEOr8I4eoV2x"
      },
      "source": [
        "### PolicyModel\n",
        "まだ実装しない（世界モデルのみをテストしてから）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VL6_IGiMoV2x"
      },
      "outputs": [],
      "source": [
        "class PolicyModel(nn.Module):\n",
        "    def __init__(self, z_dim, history_dim, action_dim, mlp_dim=512):\n",
        "        super(PolicyModel, self).__init__()\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(z_dim + history_dim, mlp_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(mlp_dim, action_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, h, z):\n",
        "        action = self.fc1(torch.cat([h, z], dim=-1))\n",
        "        return action"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwQvbtB8oV2y"
      },
      "source": [
        "### ValueModel\n",
        "まだ実装しない（世界モデルのみをテストしてから）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HM8MrWJ_oV2y"
      },
      "outputs": [],
      "source": [
        "class ValueModel(nn.Module):\n",
        "    def __init__(self, z_dim, history_dim, mlp_dim=512):\n",
        "        super(ValueModel, self).__init__()\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(z_dim + history_dim, mlp_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(mlp_dim, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, h, z):\n",
        "        value = self.fc1(torch.cat([h, z], dim=-1))\n",
        "        return value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_HtwhDnoV2y"
      },
      "source": [
        "## 学習の実装編"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifhhkfy2oV2y"
      },
      "source": [
        "### ハイパーパラメータの設定と学習の準備\n",
        "\n",
        "ハイパーパラメータを設定し，モデルやリプレイバッファを宣言して学習の準備を整えます．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpRgfhx9oV2y"
      },
      "outputs": [],
      "source": [
        "env = make_env()\n",
        "\n",
        "# リプレイバッファの宣言\n",
        "buffer_capacity = 200000  # Colabのメモリの都合上，元の実装より小さめにとっています\n",
        "replay_buffer = ReplayBuffer(\n",
        "    capacity=buffer_capacity,\n",
        "    observation_shape=env.observation_space.shape,\n",
        "    action_dim=env.action_space.shape[0],\n",
        ")\n",
        "\n",
        "# モデルの宣言\n",
        "\n",
        "# ハイパラ\n",
        "# encoder用\n",
        "grayscale = True\n",
        "category_size = 16\n",
        "class_size = 16\n",
        "# decoder用\n",
        "z_dim = category_size * class_size\n",
        "history_dim = 256 # history_dimの分だけS4-layerはコピーされるので、あまり大きすぎると計算量が大変かも\n",
        "# rewardModel用\n",
        "rewardMLP_dim = 256\n",
        "# historyEncoder用\n",
        "gMLP_dim = 512\n",
        "S4_mlp_dim = 512\n",
        "zMLP_dim = 512\n",
        "dropout = 0.2\n",
        "\n",
        "encoder = Encoder(\n",
        "    input_dim=(1 if grayscale else 3),\n",
        "    category_size=category_size,\n",
        "    class_size=class_size\n",
        ").to(device)\n",
        "\n",
        "decoder = Decoder(\n",
        "    output_dim=(1 if grayscale else 3),\n",
        "    z_dim=z_dim,\n",
        "    history_dim=history_dim\n",
        ").to(device) # z_dimはcategory_size * class_sizeとなる必要がある\n",
        "\n",
        "rewardModel = RewardModel(\n",
        "    history_dim=history_dim,\n",
        "    z_dim=z_dim,\n",
        "    mlp_dim=rewardMLP_dim\n",
        ")\n",
        "\n",
        "historyEncoder = HistoryEncoder(\n",
        "    z_dim=z_dim,\n",
        "    action_dim=env.action_space.shape[0],\n",
        "    gMLP_dim=gMLP_dim,\n",
        "    history_dim=history_dim,\n",
        "    S4_mlp_dim=S4_mlp_dim,\n",
        "    S4_n_layers=2,\n",
        "    dropout=dropout,\n",
        "    prenorm=True,\n",
        "    zMLP_dim=zMLP_dim\n",
        ")\n",
        "\n",
        "#=======================ここまで=========================\n",
        "\n",
        "# オプティマイザの宣言\n",
        "model_lr = 6e-4  # encoder, rssm, obs_model, reward_modelの学習率\n",
        "value_lr = 8e-5\n",
        "action_lr = 8e-5\n",
        "eps = 1e-4\n",
        "model_params = (\n",
        "    list(encoder.parameters())\n",
        "    + list(rssm.transition.parameters())\n",
        "    + list(rssm.observation.parameters())\n",
        "    + list(rssm.reward.parameters())\n",
        ")\n",
        "model_optimizer = torch.optim.Adam(model_params, lr=model_lr, eps=eps)\n",
        "value_optimizer = torch.optim.Adam(value_model.parameters(), lr=value_lr, eps=eps)\n",
        "action_optimizer = torch.optim.Adam(action_model.parameters(), lr=action_lr, eps=eps)\n",
        "\n",
        "# その他ハイパーパラメータ\n",
        "seed_episodes = 5  # 最初にランダム行動で探索するエピソード数\n",
        "all_episodes = 100  # 学習全体のエピソード数（300ほどで，ある程度収束します）\n",
        "test_interval = 10  # 何エピソードごとに探索ノイズなしのテストを行うか\n",
        "model_save_interval = 20  # NNの重みを何エピソードごとに保存するか\n",
        "collect_interval = 100  # 何回のNNの更新ごとに経験を集めるか（＝1エピソード経験を集めるごとに何回更新するか）\n",
        "\n",
        "action_noise_var = 0.3  # 探索ノイズの強さ\n",
        "\n",
        "batch_size = 50\n",
        "chunk_length = 50  # 1回の更新で用いる系列の長さ\n",
        "imagination_horizon = 15  # Actor-Criticの更新のために，Dreamerで何ステップ先までの想像上の軌道を生成するか\n",
        "\n",
        "\n",
        "gamma = 0.9  # 割引率\n",
        "lambda_ = 0.95  # λ-returnのパラメータ\n",
        "clip_grad_norm = 100  # gradient clippingの値\n",
        "free_nats = 3  # KL誤差（RSSMのTransitionModelにおけるpriorとposteriorの間の誤差）がこの値以下の場合，無視する"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xO91L3NMoV2z"
      },
      "outputs": [],
      "source": [
        "log_dir = \"logs\"\n",
        "writer = SummaryWriter(log_dir)\n",
        "# %tensorboard --logdir='./logs'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eokVbZFzoV2z"
      },
      "source": [
        "### 学習の実装（世界モデルのみテストする）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "We9vag6OoV2z",
        "outputId": "037e836d-3d65-4ae9-c6b4-1f1f8c4dd3d5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:174: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed a `seed` instead of using `Env.seed` for resetting the environment random number generator.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:190: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `return_info` to return information from the environment resetting.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:195: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:280: UserWarning: \u001b[33mWARN: No render modes was declared in the environment (env.metadata['render_modes'] is None or not defined), you may have trouble when calling `.render()`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
            "  logger.deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(done, (bool, np.bool8)):\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "5414"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#最初の数エピソードはランダムに行動して経験をリプレイバッファに集める\n",
        "env = make_env()\n",
        "buffer_capacity = 200000\n",
        "replay_buffer = ReplayBuffer(capacity=buffer_capacity, observation_shape=env.observation_space.shape, action_dim=env.action_space.shape[0])\n",
        "seed_episodes = 5\n",
        "for episode in range(seed_episodes):\n",
        "    obs = env.reset()\n",
        "    done = False\n",
        "    while not done:\n",
        "        action = env.action_space.sample()\n",
        "        next_obs, reward, done, _ = env.step(action)\n",
        "        replay_buffer.push(obs, action, reward, done)\n",
        "        obs = next_obs\n",
        "del env\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "j8xpj05yoV2z"
      },
      "outputs": [],
      "source": [
        "#学習結果を確認するためにTensorBoardを立ち上げておく\n",
        "log_dir = \"logs\"\n",
        "writer = SummaryWriter(log_dir)\n",
        "# %tensorboard --logdir='./logs'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goRLmViLoV20"
      },
      "source": [
        "#### オプティマイザのセットアップ関数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5raauUt_oV20",
        "outputId": "950f9075-ac66-4eb1-ddb9-53db854c09d6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "def setup_optimizer(model_params, lr, weight_decay, epochs):\n",
        "    \"\"\"\n",
        "    S4 requires a specific optimizer setup.\n",
        "\n",
        "    The S4 layer (A, B, C, dt) parameters typically\n",
        "    require a smaller learning rate (typically 0.001), with no weight decay.\n",
        "\n",
        "    The rest of the model can be trained with a higher learning rate (e.g. 0.004, 0.01)\n",
        "    and weight decay (if desired).\n",
        "    \"\"\"\n",
        "\n",
        "    # General parameters don't contain the special _optim key\n",
        "    params = [p for p in model_params if not hasattr(p, \"_optim\")]\n",
        "\n",
        "    # Create an optimizer with the general parameters\n",
        "    optimizer = optim.AdamW(params, lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    # Add parameters with special hyperparameters\n",
        "    hps = [getattr(p, \"_optim\") for p in model_params if hasattr(p, \"_optim\")]\n",
        "    hps = [\n",
        "        dict(s) for s in sorted(list(dict.fromkeys(frozenset(hp.items()) for hp in hps)))\n",
        "    ]  # Unique dicts\n",
        "    for hp in hps:\n",
        "        params = [p for p in model_params if getattr(p, \"_optim\", None) == hp]\n",
        "        optimizer.add_param_group(\n",
        "            {\"params\": params, **hp}\n",
        "        )\n",
        "\n",
        "    # Create a lr scheduler\n",
        "    # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=patience, factor=0.2)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
        "\n",
        "    # Print optimizer info\n",
        "    keys = sorted(set([k for hp in hps for k in hp.keys()]))\n",
        "    for i, g in enumerate(optimizer.param_groups):\n",
        "        group_hps = {k: g.get(k, None) for k in keys}\n",
        "        print(' | '.join([\n",
        "            f\"Optimizer group {i}\",\n",
        "            f\"{len(g['params'])} tensors\",\n",
        "        ] + [f\"{k} {v}\" for k, v in group_hps.items()]))\n",
        "\n",
        "    return optimizer, scheduler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 709
        },
        "id": "8IK7Pp3ooV20",
        "outputId": "69eb59c7-5cb3-4f26-a457-7ff4cc837c7b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:174: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed a `seed` instead of using `Env.seed` for resetting the environment random number generator.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:190: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `return_info` to return information from the environment resetting.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:195: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:280: UserWarning: \u001b[33mWARN: No render modes was declared in the environment (env.metadata['render_modes'] is None or not defined), you may have trouble when calling `.render()`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
            "  logger.deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(done, (bool, np.bool8)):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimizer group 0 | 48 tensors | lr 0.0006 | weight_decay 0.01\n",
            "Optimizer group 1 | 6 tensors | lr 0.001 | weight_decay 0.0\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "reshape(): argument 'shape' failed to unpack the object at pos 3 with error \"type must be tuple of ints,but got torch.Size\"",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-7c95f36976e4>\u001b[0m in \u001b[0;36m<cell line: 108>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-58-7c95f36976e4>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mz_cur\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposterior_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposterior_dist_no_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_next\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior_dist_no_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistoryEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_cur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mrecon_obs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_next\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0mpred_rewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrewardModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_next\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-53-babb0d5fe17e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, h, z)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: reshape(): argument 'shape' failed to unpack the object at pos 3 with error \"type must be tuple of ints,but got torch.Size\""
          ]
        }
      ],
      "source": [
        "# Training Loop\n",
        "def train_model():\n",
        "    env = make_env()\n",
        "    # Hyperparameters\n",
        "    grayscale = False\n",
        "    category_size = 32\n",
        "    class_size = 32\n",
        "    z_dim = category_size * class_size\n",
        "    history_dim = z_dim\n",
        "    rewardMLP_dim = 256\n",
        "    gMLP_dim = 512\n",
        "    S4_mlp_dim = 512\n",
        "    zMLP_dim = 512\n",
        "    dropout = 0.2\n",
        "\n",
        "    encoder = Encoder(\n",
        "        input_dim=(1 if grayscale else 3),\n",
        "        category_size=category_size,\n",
        "        class_size=class_size\n",
        "    ).to(device)\n",
        "\n",
        "    decoder = Decoder(\n",
        "        output_dim=(1 if grayscale else 3),\n",
        "        z_dim=z_dim,\n",
        "        history_dim=history_dim\n",
        "    ).to(device)\n",
        "\n",
        "    rewardModel = RewardModel(\n",
        "        history_dim=history_dim,\n",
        "        z_dim=z_dim,\n",
        "        mlp_dim=rewardMLP_dim\n",
        "    ).to(device)\n",
        "\n",
        "    historyEncoder = HistoryEncoder(\n",
        "        z_dim=z_dim,\n",
        "        action_dim=env.action_space.shape[0],\n",
        "        gMLP_dim=gMLP_dim,\n",
        "        history_dim=history_dim,\n",
        "        S4_mlp_dim=S4_mlp_dim,\n",
        "        S4_n_layers=2,\n",
        "        dropout=dropout,\n",
        "        prenorm=True,\n",
        "        zMLP_dim=zMLP_dim,\n",
        "        class_size=class_size,\n",
        "        category_size=category_size\n",
        "    ).to(device)\n",
        "\n",
        "    model_lr = 6e-4\n",
        "    EPOCHS = 100\n",
        "    # 世界モデルのパラメータたち\n",
        "    model_params = (list(encoder.parameters()) + list(decoder.parameters()) + list(rewardModel.parameters()) + list(historyEncoder.parameters()))\n",
        "\n",
        "    model_optimizer, scheduler = setup_optimizer(\n",
        "        model_params, lr=model_lr, weight_decay=weight_decay, epochs=EPOCHS\n",
        "    )\n",
        "\n",
        "\n",
        "    batch_size = 50\n",
        "    chunk_length = 50\n",
        "    explore_steps = 500 # 探索ステップ数\n",
        "    clip_grad_norm = 100\n",
        "\n",
        "    log_dir = \"logs\"\n",
        "    writer = SummaryWriter(log_dir)\n",
        "\n",
        "    # Training loop\n",
        "    for episode in range(EPOCHS):\n",
        "        env = make_env()\n",
        "        obs = env.reset()\n",
        "        for _ in range(explore_steps):\n",
        "            action = env.action_space.sample()\n",
        "            next_obs, reward, done, _ = env.step(action)\n",
        "            replay_buffer.push(obs, action, reward, done)\n",
        "            obs = next_obs\n",
        "\n",
        "        if len(replay_buffer) > batch_size * chunk_length:\n",
        "            observations, actions, rewards, dones = replay_buffer.sample(batch_size, chunk_length)\n",
        "            observations = preprocess_obs(observations)\n",
        "            observations = torch.tensor(observations, dtype=torch.float32).to(device)\n",
        "            observations = rearrange(observations, \"b t h w c -> t b c h w\")\n",
        "            actions = torch.tensor(actions, dtype=torch.float32).to(device)\n",
        "            rewards = torch.tensor(rewards, dtype=torch.float32).to(device)\n",
        "            dones = torch.tensor(dones, dtype=torch.float32).to(device)\n",
        "\n",
        "            z_cur, posterior_dist, posterior_dist_no_grad = encoder(observations)\n",
        "            h, z_next, prior_dist, prior_dist_no_grad = historyEncoder(z_cur.detach(), actions)\n",
        "            recon_obs = decoder(h, z_next)\n",
        "            pred_rewards = rewardModel(h.detach(), z_next.detach())\n",
        "\n",
        "            recon_loss = F.mse_loss(recon_obs, observations)\n",
        "            reward_loss = F.mse_loss(pred_rewards, rewards)\n",
        "            kl_loss = kl_divergence(prior_dist_no_grad, posterior_dist) + kl_divergence(prior_dist, posterior_dist_no_grad)\n",
        "            loss = recon_loss + reward_loss + kl_loss\n",
        "\n",
        "            model_optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(model_params, clip_grad_norm)\n",
        "            model_optimizer.step()\n",
        "\n",
        "            writer.add_scalar('Loss/recon_loss', recon_loss.item(), episode)\n",
        "            writer.add_scalar('Loss/reward_loss', reward_loss.item(), episode)\n",
        "\n",
        "        del env\n",
        "        gc.collect()\n",
        "        scheduler.step()\n",
        "\n",
        "    writer.close()\n",
        "\n",
        "train_model()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJ13nxcPoV20"
      },
      "source": [
        "### 学習の実装（方策モデルも含めてタスクを解く学習）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfiOqKxJoV21"
      },
      "outputs": [],
      "source": [
        "# Training Loop\n",
        "def train_model():\n",
        "    env = make_env()\n",
        "    buffer_capacity = 200000\n",
        "    replay_buffer = ReplayBuffer(capacity=buffer_capacity, observation_shape=env.observation_space.shape, action_dim=env.action_space.shape[0])\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    # Hyperparameters\n",
        "    grayscale = True\n",
        "    category_size = 16\n",
        "    class_size = 16\n",
        "    z_dim = category_size * class_size\n",
        "    history_dim = 256\n",
        "    rewardMLP_dim = 256\n",
        "    gMLP_dim = 512\n",
        "    S4_mlp_dim = 512\n",
        "    zMLP_dim = 512\n",
        "    dropout = 0.2\n",
        "    action_dim = env.action_space.shape[0]\n",
        "\n",
        "    encoder = Encoder(input_dim=(1 if grayscale else 3), category_size=category_size, class_size=class_size).to(device)\n",
        "    decoder = Decoder(output_dim=(1 if grayscale else 3), z_dim=z_dim, history_dim=history_dim).to(device)\n",
        "    rewardModel = RewardModel(history_dim=history_dim, z_dim=z_dim, mlp_dim=rewardMLP_dim).to(device)\n",
        "    historyEncoder = HistoryEncoder(z_dim=z_dim, action_dim=action_dim, gMLP_dim=gMLP_dim, history_dim=history_dim, S4_mlp_dim=S4_mlp_dim, S4_n_layers=2, dropout=dropout, prenorm=True, zMLP_dim=zMLP_dim).to(device)\n",
        "    policyModel = PolicyModel(z_dim=z_dim, history_dim=history_dim, action_dim=action_dim, mlp_dim=512).to(device)\n",
        "    valueModel = ValueModel(z_dim=z_dim, history_dim=history_dim, mlp_dim=512).to(device)\n",
        "\n",
        "    model_lr = 6e-4\n",
        "    eps = 1e-4\n",
        "    model_params = list(encoder.parameters()) + list(historyEncoder.parameters()) + list(decoder.parameters()) + list(rewardModel.parameters())\n",
        "    model_optimizer = torch.optim.Adam(model_params, lr=model_lr, eps=eps)\n",
        "    policy_optimizer = torch.optim.Adam(policyModel.parameters(), lr=model_lr, eps=eps)\n",
        "    value_optimizer = torch.optim.Adam(valueModel.parameters(), lr=model_lr, eps=eps)\n",
        "\n",
        "    batch_size = 50\n",
        "    chunk_length = 50\n",
        "    gamma = 0.9\n",
        "    lambda_ = 0.95\n",
        "    clip_grad_norm = 100\n",
        "    free_nats = 3\n",
        "\n",
        "    log_dir = \"logs\"\n",
        "    writer = SummaryWriter(log_dir)\n",
        "\n",
        "    # Training loop\n",
        "    for episode in range(100):\n",
        "        obs = env.reset()\n",
        "        done = False\n",
        "        while not done:\n",
        "            action = env.action_space.sample()\n",
        "            next_obs, reward, done, _ = env.step(action)\n",
        "            replay_buffer.push(obs, action, reward, done)\n",
        "            obs = next_obs\n",
        "\n",
        "        if len(replay_buffer) > batch_size * chunk_length:\n",
        "            observations, actions, rewards, dones = replay_buffer.sample(batch_size, chunk_length)\n",
        "            observations = torch.tensor(observations, dtype=torch.float32).to(device)\n",
        "            actions = torch.tensor(actions, dtype=torch.float32).to(device)\n",
        "            rewards = torch.tensor(rewards, dtype=torch.float32).to(device)\n",
        "            dones = torch.tensor(dones, dtype=torch.float32).to(device)\n",
        "\n",
        "            z, _ = encoder(observations)\n",
        "            h, z, _ = historyEncoder(z, actions)\n",
        "            recon_obs = decoder(h, z)\n",
        "            pred_rewards = rewardModel(h, z)\n",
        "\n",
        "            recon_loss = F.mse_loss(recon_obs, observations)\n",
        "            reward_loss = F.mse_loss(pred_rewards, rewards)\n",
        "            loss = recon_loss + reward_loss\n",
        "\n",
        "            model_optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(model_params, clip_grad_norm)\n",
        "            model_optimizer.step()\n",
        "\n",
        "            writer.add_scalar('Loss/recon_loss', recon_loss.item(), episode)\n",
        "            writer.add_scalar('Loss/reward_loss', reward_loss.item(), episode)\n",
        "\n",
        "            # Policy and Value Optimization\n",
        "            pred_values = valueModel(h, z)\n",
        "            pred_actions = policyModel(h, z)\n",
        "            action_loss = -pred_values.mean()\n",
        "            value_loss = F.mse_loss(pred_values, rewards)\n",
        "\n",
        "            policy_optimizer.zero_grad()\n",
        "            action_loss.backward()\n",
        "            nn.utils.clip_grad_norm_(policyModel.parameters(), clip_grad_norm)\n",
        "            policy_optimizer.step()\n",
        "\n",
        "            value_optimizer.zero_grad()\n",
        "            value_loss.backward()\n",
        "            nn.utils.clip_grad_norm_(valueModel.parameters(), clip_grad_norm)\n",
        "            value_optimizer.step()\n",
        "\n",
        "            writer.add_scalar('Loss/action_loss', action_loss.item(), episode)\n",
        "            writer.add_scalar('Loss/value_loss', value_loss.item(), episode)\n",
        "\n",
        "    writer.close()\n",
        "\n",
        "train_model()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "ifhhkfy2oV2y",
        "QJ13nxcPoV20"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
